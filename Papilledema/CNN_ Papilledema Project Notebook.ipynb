{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1GqZu6zmCy2vMNMZqO78DDuHvwv_9vJcp","timestamp":1671911282805},{"file_id":"1IzPbxNFQmmSYk9s14L4YjBfUgACn9mW2","timestamp":1593978024316},{"file_id":"1G7NKeneJNyRtcRxLVbbF9jYtRyuTOa-R","timestamp":1592749700622},{"file_id":"https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/Utils/Colab_25GBRAM_GPU.ipynb","timestamp":1592043804148}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"yX57gvMOAZUK"},"source":["#Papilledema Identification"]},{"cell_type":"markdown","source":["# Install Libraries and Datasets"],"metadata":{"id":"AZx9FNAE7B7n"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-inBE93CAlPR"},"outputs":[],"source":["# Installing libraries\n","\n","import tensorflow as tf\n","import random, os\n","import shutil\n","from matplotlib.image import imread\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import imageio\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import tensorflow.keras as keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, BatchNormalization\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.applications.mobilenet import MobileNet\n","from keras.metrics import AUC\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tm1bBqRmcITX"},"outputs":[],"source":["# Installing the glaucoma data set\n","\n","!wget https://www.dropbox.com/sh/wmxs51t9o9i92cj/AAAmlvKN32kyORQtmmCU_Dkwa?dl=0"]},{"cell_type":"code","source":["#Unzip the dataset\n","\n","!unzip AAAmlvKN32kyORQtmmCU_Dkwa?dl=0"],"metadata":{"id":"Ai4toHTpXzpK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Management & Exploration"],"metadata":{"id":"lWVP9MC469cQ"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","\n","# Create an empty list to store the images\n","normal_list = []\n","pseudopapilledema_list = []\n","papilledema_list = []\n","\n","# Get the list of files in the directory\n","normal_files = os.listdir('/content/Normal')\n","pseudopapilledema_files = os.listdir('/content/Pseudopapilledema')\n","papilledema_files = os.listdir('/content/Papilledema')\n","\n","for file in normal_files:\n","  file_path = os.path.join('/content/Normal', file)\n","  # Open the image\n","  image = Image.open(file_path)\n","  # Resize the image\n","  image = image.resize((224, 224))\n","  # Convert the image to a numpy array\n","  image_array = np.array(image)\n","  # Append the image to the normal_list\n","  normal_list.append(image_array)\n","\n","# Iterate over the files and append them to the pseudopapilledema_list\n","for file in pseudopapilledema_files:\n","  file_path = os.path.join('/content/Pseudopapilledema', file)\n","  # Open the image\n","  image = Image.open(file_path)\n","  # Resize the image\n","  image = image.resize((224, 224))\n","  # Convert the image to a numpy array\n","  image_array = np.array(image)\n","  # Append the image to the pseudopapilledema_list\n","  pseudopapilledema_list.append(image_array)\n","\n","# Iterate over the files and append them to the papilledema_list\n","for file in papilledema_files:\n","  file_path = os.path.join('/content/Papilledema', file)\n","  # Open the image\n","  image = Image.open(file_path)\n","  # Resize the image\n","  image = image.resize((224, 224))\n","  # Convert the image to a numpy array\n","  image_array = np.array(image)\n","  # Append the image to the papilledema_list\n","  papilledema_list.append(image_array)\n","\n","\n","# Convert the list of images to a NumPy array\n","normal_array = np.array(normal_list)\n","normal_array = normal_array[:590]\n","pseudopapilledema_array = np.array(pseudopapilledema_list)\n","papilledema_array = np.array(papilledema_list)"],"metadata":{"id":"dumMnlAyx8g9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(normal_array[0])\n","plt.show()\n","\n","plt.imshow(pseudopapilledema_array[0])\n","plt.show()\n","\n","plt.imshow(papilledema_array[0])\n","plt.show()"],"metadata":{"id":"Fs3zVNidZmLi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtL4jepPoCrT"},"outputs":[],"source":["yes_array = np.concatenate([pseudopapilledema_array, papilledema_array])\n","\n","# Combine the arrays\n","combined_array = np.concatenate([normal_array, yes_array])\n","\n","# Create a label array with the binary labels\n","zeroes = np.zeros(len(normal_array))\n","ones = np.ones(len(yes_array))\n","\n","label_array = np.concatenate([zeroes, ones])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0v8sLNHb3fs3"},"outputs":[],"source":["# Verifying that all images are the same size -- 224 x 224\n","\n","same_size = True\n","reference_shape = combined_array[0].shape\n","for i in range(1, len(combined_array)):\n","    if combined_array[i].shape != reference_shape:\n","        same_size = False\n","        break\n","\n","if same_size:\n","    print(\"All images are the same size\")\n","\n","    height, width = combined_array.shape[:2]\n","    print(\"Image size: {} x {}\".format(height, width))\n","else:\n","    print(\"Not all images are the same size\")"]},{"cell_type":"code","source":["# Printing out a few image examples\n","\n","plt.imshow(combined_array[0])\n","plt.show()\n","\n","plt.imshow(combined_array[200])\n","plt.show()\n","\n","print(len(combined_array))\n","\n","print(label_array[400])\n","print(label_array[800])"],"metadata":{"id":"76eJcuUJPF0Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download Some Images For Testing\n","\n","number = 50\n","\n","cv2.imwrite('no1.jpg', combined_array[number])"],"metadata":{"id":"fVLebg8wRo-t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Matplotlib Bar Graph Construction -- Verify Dataset\n","\n","# Count the number of no_dr0 and yes_dr1 images in the combined_array\n","num_normal = normal_array.shape[0]\n","num_papilledema = yes_array.shape[0]\n","\n","# Create a figure and axis\n","fig, ax = plt.subplots()\n","\n","# Create a bar plot with two bars, one for no_dr0 and one for yes_dr1\n","ax.bar(0, num_normal, label=\"normal\")\n","ax.bar(1, num_papilledema, label=\"papilledema\")\n","\n","# Set the x-axis tick labels\n","ax.set_xticks([0, 1, 2])\n","ax.set_xticklabels([\"normal\", \"papilledema\"])\n","\n","# Set the y-axis tick labels\n","ax.set_ylabel(\"Number of images\")\n","\n","# Add labels to the bar graphs\n","ax.text(0, num_normal + 50, str(num_normal), ha=\"center\", va=\"bottom\", fontsize=14, color=\"red\", weight=\"bold\")\n","ax.text(1, num_papilledema + 50, str(num_papilledema), ha=\"center\", va=\"bottom\", fontsize=14, color=\"red\", weight=\"bold\")\n","\n","# Add a legend\n","ax.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"xLu_g_W_PbJ9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y9xOGAYZwh1d"},"source":["#Machine Learning Algorithm\n"]},{"cell_type":"code","source":["# Necessary imports\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Extract the features and labels from the combined_array_2D array:\n","X = combined_array # features (colored images)\n","y = label_array # labels (diagnosis of papilledema)\n","\n","# Reshape the features to have 4 dimensions (batch_size, height, width, channels)\n","X = X.reshape((X.shape[0], X.shape[1], X.shape[2], 3))\n","\n","# Split the dataset into training, test, and validation sets:\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1 / 0.8, random_state=42)\n","\n","# Create the data generator for data augmentation\n","datagen = ImageDataGenerator (\n","  rescale=1./255,\n","  rotation_range=45,\n","  width_shift_range=0.2,\n","  height_shift_range=0.2,\n","  shear_range=0.2,\n","  zoom_range=0.2,\n","  horizontal_flip=True,\n","  fill_mode='nearest'\n",")\n","\n","# Create the CNN model\n","model = Sequential()\n","\n","model.add(Conv2D(32, kernel_size=(3,3), kernel_initializer='he_uniform', activation='relu', input_shape=(X.shape[1], X.shape[2], 3)))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Conv2D(64, kernel_size=(3,3), kernel_initializer='he_uniform', activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Conv2D(64, kernel_size=(3,3), kernel_initializer='he_uniform', activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model on the augmented data\n","history = model.fit(\n","  datagen.flow(X_train, y_train, batch_size=64),\n","  epochs=30,\n","  validation_data=(X_val, y_val),\n","  verbose=1\n",")\n","\n","# Evaluate the model on the test data\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"iwuHzAQTAilj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Confusion Matrix\n","\n","- True Positives, True Negatives, False Positives, False Negatives"],"metadata":{"id":"SzzaS4-2E6Lw"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","# Predict the labels for the test data\n","y_pred = model.predict(X_test)\n","\n","# Convert the predicted probabilities to binary labels\n","y_pred = (y_pred > 0.5).astype(int)\n","\n","# Calculate the confusion matrix\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# Use the 'Blues' colormap\n","plt.imshow(cm, cmap='Blues')\n","\n","# Define the labels for the cells\n","labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n","\n","# Add labels to the cells\n","for i in range(2):\n","  for j in range(2):\n","    plt.text(j, i, labels[2 * i + j], ha='center', va='center', color='black')\n","\n","# Add the actual numbers to the cells\n","for i in range(2):\n","  for j in range(2):\n","    plt.text(j, i + 0.2, cm[i, j], ha='center', va='center', color='black')\n","\n","# Adjust the axis labels and title\n","plt.colorbar()\n","plt.xlabel('Predicted label')\n","plt.ylabel('True label')\n","plt.title('True vs. Predicted Detection for Papilledema')\n","\n","# Adjust the figure size\n","plt.figure(figsize=(8, 8))\n","\n","# Display the plot\n","plt.show()\n","\n","# Generate a classification report\n","report = classification_report(y_test, y_pred, target_names=['Negative', 'Positive'])\n","print(report)"],"metadata":{"id":"vL0frpawFBiY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ROC Curve"],"metadata":{"id":"H7mbbpSXTSQ3"}},{"cell_type":"code","source":["# ROC\n","from sklearn.metrics import roc_curve\n","y_preds = model.predict(X_test).ravel()\n","\n","fpr, tpr, thresholds = roc_curve(y_test, y_preds)\n","plt.figure(1)\n","plt.plot([0, 1], [0, 1], 'y--')\n","plt.plot(fpr, tpr, marker='.')\n","plt.xlabel('False positive rate')\n","plt.ylabel('True positive rate')\n","plt.title('ROC Curve for Papilledema')\n","plt.show()\n","\n","from sklearn.metrics import roc_auc_score\n","auc = roc_auc_score(y_test, y_preds)\n","print(auc)"],"metadata":{"id":"UnJ1g76hTRt-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T2dLEi6qFwdv"},"outputs":[],"source":["# Learning Curve and Loss Curve:\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['accuracy'], label='accuracy')\n","plt.plot(history.history['val_accuracy'], label='val_accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.ylim([0.5, 1])\n","plt.legend(loc='lower right')\n","\n","plt.plot(history.history['loss'], label='loss')\n","plt.plot(history.history['val_loss'], label='val_loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('loss')\n","plt.ylim([0.5, 1])\n","plt.legend(loc='lower right')"]},{"cell_type":"markdown","source":["# TensorFlow Lite Implementation -- Android App\n"],"metadata":{"id":"1WW_Ai6w6yrv"}},{"cell_type":"code","source":["# Convert Model to TensorFlow Lite -- App Usage -- DO NOT RUN THIS EVERYTIME\n","\n","# Convert the model to TensorFlow Lite\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# Save the model to file\n","with open('model2.tflite', 'wb') as f:\n","  f.write(tflite_model)"],"metadata":{"id":"YAaxbPMAVUll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test the TensorFlow Lite Model\n","\n","img = cv2.imread(\"no1.jpg\")\n","img = cv2.resize(img, (224,224))\n","img = np.array(img, dtype=\"float32\")\n","img = np.reshape(img, (1,224,224,3))\n","\n","# Load the TFLite model and allocate tensors.\n","interpreter = tf.lite.Interpreter(model_path=\"model2.tflite\")\n","interpreter.allocate_tensors()\n","\n","# Get input and output tensors.\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","# Test the model on random input data.\n","input_shape = input_details[0]['shape']\n","\n","print(input_details)\n","print(output_details)\n","\n","interpreter.set_tensor(input_details[0]['index'], img)\n","\n","interpreter.invoke()\n","\n","# The function `get_tensor()` returns a copy of the tensor data.\n","# Use `tensor()` in order to get a pointer to the tensor.\n","output_data = interpreter.get_tensor(output_details[0]['index'])\n","print(output_data)"],"metadata":{"id":"f9kXOwRJ6XVI"},"execution_count":null,"outputs":[]}]}