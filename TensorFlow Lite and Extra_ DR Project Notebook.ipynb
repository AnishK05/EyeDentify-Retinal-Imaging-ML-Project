{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1GqZu6zmCy2vMNMZqO78DDuHvwv_9vJcp","timestamp":1671911282805},{"file_id":"1IzPbxNFQmmSYk9s14L4YjBfUgACn9mW2","timestamp":1593978024316},{"file_id":"1G7NKeneJNyRtcRxLVbbF9jYtRyuTOa-R","timestamp":1592749700622},{"file_id":"https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/Utils/Colab_25GBRAM_GPU.ipynb","timestamp":1592043804148}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kwhQwI_zBGTN"},"source":["# Data Exploration\n","\n","- size: # of images, # of pixels in each, is it the same for all\n","- imshow to print out a few examples\n","- bar graph for showing balanced dataset\n","- relevant statistics: avg, std, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0v8sLNHb3fs3"},"outputs":[],"source":["# Verifying that all images are the same size -- 224 x 224\n","\n","same_size = True\n","reference_shape = combined_array[0].shape\n","for i in range(1, len(combined_array)):\n","    if combined_array[i].shape != reference_shape:\n","        same_size = False\n","        break\n","\n","if same_size:\n","    print(\"All images are the same size\")\n","\n","    height, width = combined_array.shape[:2]\n","    print(\"Image size: {} x {}\".format(height, width))\n","else:\n","    print(\"Not all images are the same size\")"]},{"cell_type":"code","source":["#Verifying that there are the same number of images in both sets -- balanced dataset\n","\n","num_images1 = no_dr0.shape[0]\n","num_images2 = yes_dr1.shape[0]\n","\n","print(num_images1)\n","print(num_images2)"],"metadata":{"id":"QSLI9xxaOlp8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Printing out a few image examples\n","\n","plt.imshow(combined_array[1])\n","plt.show()\n","\n","plt.imshow(combined_array[467])\n","plt.show()"],"metadata":{"id":"76eJcuUJPF0Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Relevant Statistics -- Pixel Size\n","\n","mean = np.mean(combined_array)\n","std = np.std(combined_array)\n","\n","print(f\"Mean: {mean}\")\n","print(f\"Standard deviation: {std}\")"],"metadata":{"id":"4b5pbOD9TsiK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PKxjQiAoBJlR"},"source":["#Data PreProcessing\n","\n","Note: Iteratively save each processed version of the image data as its own new variable\n","\n","- Normalizing\n","- Greyscale??\n","\n","Probably will not need to (Data Augmentation):\n","- crop\n","- rotate\n","- flip\n"]},{"cell_type":"code","source":["#Normalizing the images and saving each processed version of the image data as its own new variable\n","\n","# Create an empty list to store the normalized images\n","normalized_images = []\n","\n","# Iterate over the images in the combined_array\n","for image in combined_array:\n","    # Standardize the image by subtracting the mean and dividing by the standard deviation\n","    standardized_image = (image - mean) / std\n","    # Append the standardized image to the list\n","    normalized_images.append(standardized_image)\n","\n","# Convert the list of normalized images to a NumPy array\n","normalized_array = np.array(normalized_images)\n","\n","# Print Test Output\n","plt.imshow(normalized_array[1])\n","plt.show()"],"metadata":{"id":"FhdEIhiEWFIb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Grayscale the images\n","\n","# Create an empty list to store the grayscale images\n","gray_images = []\n","\n","# Iterate over the images in the normalized_array\n","for image in combined_array:\n","    # Convert the image to grayscale\n","    gray_image = cv2.cvtColor(np.asarray(image, dtype=np.float32), cv2.COLOR_BGR2GRAY)\n","    # Append the grayscale image to the list\n","    gray_images.append(gray_image)\n","\n","# Convert the list of grayscale images to a NumPy array\n","gray_array = np.array(gray_images)\n","\n","# Print Outputs\n","plt.imshow(gray_array[1], cmap = plt.cm.gray)\n","plt.show()"],"metadata":{"id":"p1eHbLl80tsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Apply Histogram Equalization\n","\n","# Create an empty list to store the equalized images\n","equalized_images = []\n","\n","# Iterate over the images in the gray_array\n","for image in gray_array:\n","    # Convert the image to an 8-bit single channel image\n","    image = cv2.convertScaleAbs(image)\n","    # Apply histogram equalization to the image\n","    equalized_image = cv2.equalizeHist(image)\n","    # Append the equalized image to the list\n","    equalized_images.append(equalized_image)\n","\n","# Convert the list of equalized images to a NumPy array\n","equalized_array = np.array(equalized_images)\n","\n","\n","# Print Outputs\n","plt.imshow(equalized_array[1], cmap = plt.cm.gray)\n","plt.show()"],"metadata":{"id":"Z6pYc4tiWPhk"},"execution_count":null,"outputs":[]}]}